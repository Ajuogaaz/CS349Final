{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d21693ab-0e9c-4bc3-97e2-e848de41406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"R0KLAMJVMGF60UMF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a67a59c-28ff-425b-9c42-af5d92e9520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import json\n",
    "\n",
    "\n",
    "def save_dataset(symbol):\n",
    "    api_key = \"R0KLAMJVMGF60UMF\"\n",
    "\n",
    "    ts = TimeSeries(key=api_key, output_format='pandas')\n",
    "    data, meta_data = ts.get_daily(symbol, outputsize='full')\n",
    "\n",
    "    data.to_csv(f'./{symbol}_daily.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62436ac1-181c-45b8-a3ef-3ce82a6ca153",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset('MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af09e346-8952-475b-9abf-a8f9a7b09f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "history_points = 50\n",
    "\n",
    "def csv_to_dataset(csv_path):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    data = data.drop('date', axis=1)\n",
    "    data = data.drop(0, axis=0)\n",
    "   \n",
    "\n",
    "    data_normaliser = preprocessing.MinMaxScaler()\n",
    "    data_normalised = data_normaliser.fit_transform(data)\n",
    "     # using the last {history_points} open high low close volume data points, predict the next open value\n",
    "    ohlcv_histories_normalised =      np.array([data_normalised[i  : i + history_points].copy() for i in range(len(data_normalised) - history_points)])\n",
    "    next_day_open_values_normalised = np.array([data_normalised[:,0][i + history_points].copy() for i in range(len(data_normalised) - history_points)])\n",
    "    next_day_open_values_normalised = np.expand_dims(next_day_open_values_normalised, -1)\n",
    "\n",
    "    next_day_open_values = np.array([data[:,0][i + history_points].copy() for i in range(len(data) - history_points)])\n",
    "    next_day_open_values = np.expand_dims(next_day_open_values_normalised, -1)\n",
    "\n",
    "    y_normaliser = preprocessing.MinMaxScaler()\n",
    "    y_normaliser.fit(np.expand_dims( next_day_open_values ))\n",
    "    \n",
    "    assert ohlcv_histories_normalised.shape[0] == next_day_open_values_normalised.shape[0]\n",
    "    return ohlcv_histories_normalised, next_day_open_values_normalised, next_day_open_values, y_normaliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d30dc-c71f-4f7b-8729-8b67f8d263c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv_histories, next_day_open_values, unscaled_y, y_normaliser = csv_to_dataset('MSFT_daily.csv')\n",
    "\n",
    "test_split = 0.9 # the percent of data to be used for testing\n",
    "n = int(ohlcv_histories.shape[0] * test_split)\n",
    "\n",
    "# splitting the dataset up into train and test sets\n",
    "\n",
    "ohlcv_train = ohlcv_histories[:n]\n",
    "y_train = next_day_open_values[:n]\n",
    "\n",
    "ohlcv_test = ohlcv_histories[n:]\n",
    "y_test = next_day_open_values[n:]\n",
    "\n",
    "unscaled_y_test = unscaled_y[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361247ae-fa82-4ec3-8d24-fde1069c831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "np.random.seed(4)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(4)\n",
    "\n",
    "lstm_input = Input(shape=(history_points, 5), name='lstm_input')\n",
    "x = LSTM(50, name='lstm_0')(lstm_input)\n",
    "x = Dropout(0.2, name='lstm_dropout_0')(x)\n",
    "x = Dense(64, name='dense_0')(x)\n",
    "x = Activation('sigmoid', name='sigmoid_0')(x)\n",
    "x = Dense(1, name='dense_1')(x)\n",
    "output = Activation('linear', name='linear_output')(x)\n",
    "model = Model(inputs=lstm_input, outputs=output)\n",
    "\n",
    "adam = optimizers.Adam(lr=0.0005)\n",
    "\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a5914f-2161-40d3-a0fa-23c0212e5f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adabf27-8539-41d9-8b8f-4ec27c6f5ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
